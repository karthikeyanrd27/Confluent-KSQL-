from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import *

from pyspark import SparkContext, SparkConf
from pyspark.sql import SQLContext
from pyspark.context import SparkContext
from pyspark.sql.session import SparkSession
from pyspark.streaming import StreamingContext
from pyspark.sql import SQLContext
from pyspark.sql.types import *
import pandas as pd


spark1 = SparkSession \
            .builder \
            .appName("test") \
            .getOrCreate()


data=[{  "name": "Karthi","city":"Rasipalayam"}]
df=spark1.sparkContext.parallelize(data).toDF()
s=df.show()


conf = SparkConf()
conf.setMaster("local[4]")
conf.setAppName("Spark Cassandra")
conf.set("spark.cassandra.connection.host","localhost:9042")

df.write\
.format("org.apache.spark.sql.cassandra")\
.mode('append')\
.options(table="mydetails", keyspace="key1")\
.save()
